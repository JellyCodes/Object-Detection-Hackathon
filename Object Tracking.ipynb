{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment and run if wget is not installed\n",
    "#!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = \"my_centernet_model\"\n",
    "PRETRAINED_MODEL_NAME = \"centernet_resnet50_v1_fpn_512x512_coco17_tpu-8\"\n",
    "PRETRAINED_MODEL_URL = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_resnet50_v1_fpn_512x512_coco17_tpu-8.tar.gz\"\n",
    "LABELMAP_NAME = \"person_label_map.pbtxt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the needed paths\n",
    "paths = {\n",
    "    'PROTOC_PATH': os.path.join('hackathon','protoc'),\n",
    "    'SCRIPTS_PATH': os.path.join('hackathon','scripts'),\n",
    "    'ANNOTATION_PATH': os.path.join('hackathon','workspace', 'annotation'),\n",
    "    'MODEL_API_PATH': os.path.join('hackathon','models'),\n",
    "    'MODEL_PATH': os.path.join('hackathon','workspace', 'model', CUSTOM_MODEL_NAME),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('hackathon','workspace', 'pre-trained_model'),\n",
    "    'IMAGE_PATH': os.path.join('hackathon','workspace', 'images'),\n",
    "    'TRAIN_IMAGE_PATH': os.path.join('hackathon', 'workspace', 'images', 'train'),\n",
    "    'TEST_IMAGE_PATH': os.path.join('hackathon', 'workspace', 'images', 'test'),\n",
    "    'PROTOC_PATH': os.path.join('hackathon', 'protoc')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do not run!\n",
    "#!tar -czf {os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')} {paths['TRAIN_IMAGE_PATH']} {paths['TEST_IMAGE_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy the archive.tar.gz file to the images folder before running this cell\n",
    "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
    "if os.path.exists(ARCHIVE_FILES):\n",
    "  !tar -zxvf {ARCHIVE_FILES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the cells below to install tensorflow object detection api and protocol buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(paths['MODEL_API_PATH'], 'research', 'object_detection')):\n",
    "    #this will clone the model api to our specified model path\n",
    "    !git clone https://github.com/tensorflow/models {paths['MODEL_API_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "    wget.download(url)\n",
    "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. \n",
    "    !copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py \n",
    "    !python setup.py build \n",
    "    !python setup.py install\n",
    "    !cd Tensorflow/models/research/slim && pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "    #downloading a pre-trained model to use\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "\n",
    "    #move the downloaded model to our pretrained model folder\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "\n",
    "    #change into the pretrained model folder and extract the file\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a label map for the dataset\n",
    "\n",
    "LABELMAP = os.path.join(paths['ANNOTATION_PATH'], LABELMAP_NAME)\n",
    "labels = [{'name': 'Person', 'id': 1}]\n",
    "\n",
    "with open(LABELMAP, 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname: \\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid: {}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!\n",
    "PIPELINE_CONFIG = os.path.join('hackathon', 'workspace','model', CUSTOM_MODEL_NAME, 'pipeline.config')\n",
    "TFRECORD_SCRIPT = os.path.join(paths['SCRIPTS_PATH'], 'generate_tfrecord.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TFRECORD_SCRIPT):\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a tensorflow record file for training and testing dataset\n",
    "\n",
    "!python {TFRECORD_SCRIPT} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {LABELMAP} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.tfrecord')} \n",
    "!python {TFRECORD_SCRIPT} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {LABELMAP} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.tfrecord')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy pretrained model pipeline configuration to our custom model\n",
    "\n",
    "!copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['MODEL_PATH'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import object_detection\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom model pipeline configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "\n",
    "with tf.io.gfile.GFile(PIPELINE_CONFIG, \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)\n",
    "    \n",
    "pipeline_config.model.center_net.num_classes = 1\n",
    "pipeline_config.train_config.batch_size = 2\n",
    "pipeline_config.train_config.optimizer.adam_optimizer.learning_rate.cosine_decay_learning_rate.learning_rate_base = 0.01\n",
    "pipeline_config.train_config.optimizer.adam_optimizer.learning_rate.cosine_decay_learning_rate.total_steps = 50000\n",
    "pipeline_config.train_config.optimizer.adam_optimizer.learning_rate.cosine_decay_learning_rate.warmup_learning_rate = 0.005\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path = os.path.join(paths['ANNOTATION_PATH'], LABELMAP_NAME)\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.tfrecord')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = os.path.join(paths['ANNOTATION_PATH'], LABELMAP_NAME)\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.tfrecord')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(PIPELINE_CONFIG, \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['MODEL_API_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=5000\".format(TRAINING_SCRIPT, paths['MODEL_PATH'], PIPELINE_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['MODEL_PATH'], PIPELINE_CONFIG, paths['MODEL_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import visualization_utils as vis_utils\n",
    "from object_detection.builders import model_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the detection model\n",
    "config = config_util.get_configs_from_pipeline_file(PIPELINE_CONFIG)\n",
    "model = model_builder.build(model_config=config['model'], is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore checkpoint from disk to use for detection\n",
    "checkpoint= tf.compat.v2.train.Checkpoint(model)\n",
    "checkpoint_path = os.path.join(paths['MODEL_PATH'], 'ckpt-6')\n",
    "checkpoint.restore(checkpoint_path).expect_partial() # expect_partial() to avoid warning of unused checkpoint indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function #converts the code below to tensorflow graph function for better performance\n",
    "def detection(image):\n",
    "    image, shape = model.preprocess(image)\n",
    "    prediction = model.predict(image, shape)\n",
    "    detection = model.postprocess(prediction, shape)\n",
    "    return detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting from an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from object_detection.utils import label_map_util\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the appropriate parameter and converting the image/frame into required format(numpy arrays)\n",
    "def detection_inference(media_type):\n",
    "    converted_img = np.array(media_type)\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(converted_img, 0), dtype=tf.float32)\n",
    "    category_index = label_map_util.create_category_index_from_labelmap(LABELMAP)\n",
    "\n",
    "    result_dict = detection(input_tensor)\n",
    "    num_detections = int(result_dict.pop('num_detections'))\n",
    "\n",
    "    result_dict = {key: value[0, :num_detections].numpy() for key, value in result_dict.items()}\n",
    "    result_dict['num_detections'] = num_detections\n",
    "    result_dict['detection_classes'] = result_dict['detection_classes'].astype(np.int64)\n",
    "    \n",
    "    vis_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        converted_img,\n",
    "        result_dict['detection_boxes'],\n",
    "        result_dict['detection_classes']+1,\n",
    "        result_dict['detection_scores'],\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=1,\n",
    "        min_score_thresh=0.5,\n",
    "        line_thickness=3\n",
    "    )\n",
    "    return converted_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', '12.avi_snapshot_07.25_[2021.06.21_14.35.07].jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(IMAGE_PATH)\n",
    "converted_img = detection_inference(image)\n",
    "\n",
    "rect_image = cv2.cvtColor(converted_img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(rect_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(vis_utils.visualize_boxes_and_labels_on_image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
